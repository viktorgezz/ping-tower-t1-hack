import aiohttp
import asyncio
from urllib.parse import urlparse
import time
from typing import Dict, List, Optional
import ssl
import json
from datetime import datetime, timezone
import asyncpg
from bs4 import BeautifulSoup
import re
import logging
from telegram_service import telegram_service

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class EndpointTester:
    def __init__(self, max_concurrent: int = 50, timeout: int = 30):
        self.max_concurrent = max_concurrent
        self.timeout = timeout
        self.session = None
        self.ssl_context = ssl.create_default_context()
        self.ssl_context.check_hostname = False
        self.ssl_context.verify_mode = ssl.CERT_NONE

    async def init_session(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–π —Å–µ—Å—Å–∏–∏"""
        connector = aiohttp.TCPConnector(
            limit=self.max_concurrent,
            ssl=self.ssl_context,
            force_close=True
        )
        self.session = aiohttp.ClientSession(
            connector=connector,
            timeout=aiohttp.ClientTimeout(total=self.timeout)
        )

    async def close_session(self):
        """–ó–∞–∫—Ä—ã—Ç–∏–µ —Å–µ—Å—Å–∏–∏"""
        if self.session:
            await self.session.close()

    async def test_endpoint(self, url: str) -> Dict:
        """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–¥–Ω–æ–≥–æ —ç–Ω–¥–ø–æ–∏–Ω—Ç–∞ —Å —Å–±–æ—Ä–æ–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏"""
        result = {
            'url': url,
            'timestamp': datetime.now(timezone.utc).isoformat(),
            'success': False,
            'error': None,
            'response_time': None,
            'status_code': None,
            'content_type': None,
            'content_length': None,
            'headers': {},
            'is_https': False,
            'technology_stack': [],
            'security_headers': {},
            'content_analysis': {},
            'additional_checks': {},
            'redirect_chain': []
        }

        start_time = time.time()

        try:
            async with self.session.get(
                    url,
                    allow_redirects=True,
                    ssl=self.ssl_context
            ) as response:
                # –ë–∞–∑–æ–≤–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
                result['response_time'] = time.time() - start_time
                result['status_code'] = response.status
                result['content_type'] = response.headers.get('Content-Type')
                result['content_length'] = response.headers.get('Content-Length')
                result['success'] = 200 <= response.status < 400
                result['is_https'] = response.url.scheme == 'https'
                
                # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –≤ Telegram –ø—Ä–∏ —Å—Ç–∞—Ç—É—Å–µ 500
                if response.status == 500:
                    error_message = f"–í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –æ—à–∏–±–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞ (500) –¥–ª—è URL: {url}"
                    logger.warning(f"–û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ –æ—à–∏–±–∫–∞ 500: {url}")
                    try:
                        telegram_service.send_error_notification(
                            url=url,
                            status_code=500,
                            error_message="–í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –æ—à–∏–±–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞"
                        )
                    except Exception as e:
                        logger.error(f"–û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ Telegram —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è: {e}")

                # –ó–∞–≥–æ–ª–æ–≤–∫–∏
                result['headers'] = dict(response.headers)

                # –ê–Ω–∞–ª–∏–∑ —Ü–µ–ø–æ—á–∫–∏ —Ä–µ–¥–∏—Ä–µ–∫—Ç–æ–≤
                if hasattr(response, 'history'):
                    result['redirect_chain'] = [str(res.url) for res in response.history]

                # –ê–Ω–∞–ª–∏–∑ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏
                self._analyze_security_headers(result, response.headers)

                # –ê–Ω–∞–ª–∏–∑ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–≥–æ —Å—Ç–µ–∫–∞
                self._analyze_technology_stack(result, response.headers)

                # –ß—Ç–µ–Ω–∏–µ –∏ –∞–Ω–∞–ª–∏–∑ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
                try:
                    content = await response.read()
                    if content and result['content_type']:
                        self._analyze_content(result, content, result['content_type'])
                except Exception as e:
                    logger.warning(f"Content analysis failed for {url}: {str(e)}")
                    result['content_analysis']['error'] = str(e)

                # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ SSL (—Ç–æ–ª—å–∫–æ –¥–ª—è HTTPS)
                if result['is_https']:
                    try:
                        ssl_info = {}
                        if hasattr(response.connection, 'ssl_object'):
                            ssl_obj = response.connection.ssl_object
                            ssl_info = {
                                'cipher': ssl_obj.cipher(),
                                'protocol': ssl_obj.version(),
                            }
                        result['ssl_info'] = ssl_info
                    except Exception as e:
                        logger.warning(f"SSL info extraction failed for {url}: {str(e)}")
                        result['ssl_info'] = {'error': str(e)}

        except aiohttp.ClientError as e:
            result['error'] = str(e)
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –æ—à–∏–±–∫–∞—Ö —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è
            try:
                telegram_service.send_error_notification(
                    url=url,
                    status_code=0,  # 0 –æ–∑–Ω–∞—á–∞–µ—Ç –æ—à–∏–±–∫—É —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è
                    error_message=f"–û—à–∏–±–∫–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è: {str(e)}"
                )
            except Exception as telegram_error:
                logger.error(f"–û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ Telegram —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è: {telegram_error}")
        except Exception as e:
            result['error'] = f"Unexpected error: {str(e)}"
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ –Ω–µ–æ–∂–∏–¥–∞–Ω–Ω—ã—Ö –æ—à–∏–±–∫–∞—Ö
            try:
                telegram_service.send_error_notification(
                    url=url,
                    status_code=0,  # 0 –æ–∑–Ω–∞—á–∞–µ—Ç –Ω–µ–æ–∂–∏–¥–∞–Ω–Ω—É—é –æ—à–∏–±–∫—É
                    error_message=f"–ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {str(e)}"
                )
            except Exception as telegram_error:
                logger.error(f"–û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ Telegram —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è: {telegram_error}")

        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥–ª—è —É—Å–ø–µ—à–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
        if result['success']:
            try:
                await self._perform_additional_checks(result, url)
            except Exception as e:
                logger.warning(f"Additional checks failed for {url}: {str(e)}")
                result['additional_checks']['error'] = str(e)

        return result

    def _analyze_security_headers(self, result: Dict, headers):
        """–ê–Ω–∞–ª–∏–∑ security headers"""
        security_headers = {
            'strict-transport-security': headers.get('Strict-Transport-Security'),
            'x-content-type-options': headers.get('X-Content-Type-Options'),
            'x-frame-options': headers.get('X-Frame-Options'),
            'x-xss-protection': headers.get('X-XSS-Protection'),
            'content-security-policy': headers.get('Content-Security-Policy'),
            'referrer-policy': headers.get('Referrer-Policy'),
            'permissions-policy': headers.get('Permissions-Policy'),
            'access-control-allow-origin': headers.get('Access-Control-Allow-Origin'),
            'access-control-allow-methods': headers.get('Access-Control-Allow-Methods'),
        }
        result['security_headers'] = security_headers

    def _analyze_technology_stack(self, result: Dict, headers):
        """–ê–Ω–∞–ª–∏–∑ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–≥–æ —Å—Ç–µ–∫–∞ –ø–æ –∑–∞–≥–æ–ª–æ–≤–∫–∞–º"""
        technologies = []

        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–π –ø–æ –∑–∞–≥–æ–ª–æ–≤–∫–∞–º
        server = headers.get('Server', '').lower()
        if 'nginx' in server:
            technologies.append('nginx')
        elif 'apache' in server:
            technologies.append('apache')
        elif 'iis' in server:
            technologies.append('iis')

        powered_by = headers.get('X-Powered-By', '').lower()
        if 'php' in powered_by:
            technologies.append('php')
        elif 'asp.net' in powered_by:
            technologies.append('asp.net')
        elif 'node' in powered_by:
            technologies.append('node.js')

        # –ü–æ –∑–∞–≥–æ–ª–æ–≤–∫–∞–º –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
        if headers.get('X-Generator'):
            technologies.append(headers.get('X-Generator').split()[0].lower())

        result['technology_stack'] = technologies

    def _analyze_content(self, result: Dict, content: bytes, content_type: str):
        """–ê–Ω–∞–ª–∏–∑ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ –æ—Ç–≤–µ—Ç–∞"""
        content_analysis = {}

        try:
            # –î–ª—è HTML –∫–æ–Ω—Ç–µ–Ω—Ç–∞
            if 'text/html' in content_type:
                soup = BeautifulSoup(content, 'html.parser')

                # –ú–µ—Ç–∞-–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
                content_analysis['title'] = soup.title.string if soup.title else None

                # –ú–µ—Ç–∞-—Ç–µ–≥–∏
                meta_tags = {}
                for meta in soup.find_all('meta'):
                    name = meta.get('name') or meta.get('property') or meta.get('http-equiv')
                    if name:
                        meta_tags[name.lower()] = meta.get('content')
                content_analysis['meta_tags'] = meta_tags

                # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ª–µ–º–µ–Ω—Ç–æ–≤
                content_analysis['element_count'] = {
                    'links': len(soup.find_all('a')),
                    'images': len(soup.find_all('img')),
                    'scripts': len(soup.find_all('script')),
                    'stylesheets': len(soup.find_all('link', rel='stylesheet')),
                    'forms': len(soup.find_all('form')),
                }

                # –ü–æ–∏—Å–∫ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–π –≤ –∫–æ–Ω—Ç–µ–Ω—Ç–µ
                content_str = content.decode('utf-8', errors='ignore').lower()
                tech_indicators = {
                    'wordpress': ['wp-content', 'wp-includes', 'wordpress'],
                    'drupal': ['drupal', 'sites/all'],
                    'joomla': ['joomla', 'media/jui'],
                    'react': ['react', 'react-dom'],
                    'vue': ['vue.js', 'vue@'],
                    'angular': ['angular', 'ng-'],
                    'jquery': ['jquery', '$().'],
                    'bootstrap': ['bootstrap', 'btn-primary'],
                }

                detected_tech = []
                for tech, indicators in tech_indicators.items():
                    if any(indicator in content_str for indicator in indicators):
                        detected_tech.append(tech)

                result['technology_stack'].extend(detected_tech)
                result['technology_stack'] = list(set(result['technology_stack']))

            # –î–ª—è JSON –∫–æ–Ω—Ç–µ–Ω—Ç–∞
            elif 'application/json' in content_type:
                try:
                    json_data = json.loads(content.decode('utf-8'))
                    content_analysis['json_valid'] = True
                    if isinstance(json_data, dict):
                        content_analysis['json_keys'] = list(json_data.keys())
                        content_analysis['json_size'] = len(json.dumps(json_data))
                    else:
                        content_analysis['json_type'] = type(json_data).__name__
                        content_analysis['json_size'] = len(content)
                except:
                    content_analysis['json_valid'] = False

            # –î–ª—è —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
            elif 'text/' in content_type:
                content_str = content.decode('utf-8', errors='ignore')
                content_analysis['line_count'] = len(content_str.split('\n'))
                content_analysis['word_count'] = len(content_str.split())
                content_analysis['character_count'] = len(content_str)

            # –î–ª—è XML –∫–æ–Ω—Ç–µ–Ω—Ç–∞
            elif 'application/xml' in content_type or 'text/xml' in content_type:
                content_str = content.decode('utf-8', errors='ignore')
                content_analysis['xml_size'] = len(content_str)
                content_analysis['has_xml_declaration'] = content_str.startswith('<?xml')

        except Exception as e:
            content_analysis['analysis_error'] = str(e)

        result['content_analysis'] = content_analysis

    async def _perform_additional_checks(self, result: Dict, url: str):
        """–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏"""
        parsed_url = urlparse(url)
        additional_checks = {}

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ robots.txt
        if parsed_url.scheme and parsed_url.netloc:
            robots_url = f"{parsed_url.scheme}://{parsed_url.netloc}/robots.txt"
            try:
                async with self.session.get(robots_url, timeout=10) as response:
                    additional_checks['robots_txt'] = {
                        'exists': response.status == 200,
                        'status_code': response.status,
                        'content_type': response.headers.get('Content-Type')
                    }
            except:
                additional_checks['robots_txt'] = {'exists': False}

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ sitemap.xml
        sitemap_url = f"{parsed_url.scheme}://{parsed_url.netloc}/sitemap.xml"
        try:
            async with self.session.get(sitemap_url, timeout=10) as response:
                additional_checks['sitemap_xml'] = {
                    'exists': response.status == 200,
                    'status_code': response.status,
                    'content_type': response.headers.get('Content-Type')
                }
        except:
            additional_checks['sitemap_xml'] = {'exists': False}

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ favicon.ico
        favicon_url = f"{parsed_url.scheme}://{parsed_url.netloc}/favicon.ico"
        try:
            async with self.session.get(favicon_url, timeout=10) as response:
                additional_checks['favicon'] = {
                    'exists': response.status == 200,
                    'content_type': response.headers.get('Content-Type'),
                    'size': response.headers.get('Content-Length')
                }
        except:
            additional_checks['favicon'] = {'exists': False}

        result['additional_checks'] = additional_checks

    async def test_multiple_endpoints(self, urls: List[str]) -> List[Dict]:
        """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–Ω–æ–∂–µ—Å—Ç–≤–∞ —ç–Ω–¥–ø–æ–∏–Ω—Ç–æ–≤"""
        if not self.session:
            await self.init_session()

        tasks = []
        for url in urls:
            task = asyncio.create_task(self.test_endpoint(url))
            tasks.append(task)

        results = await asyncio.gather(*tasks, return_exceptions=True)

        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏—Å–∫–ª—é—á–µ–Ω–∏–π
        processed_results = []
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                processed_results.append({
                    'url': urls[i],
                    'timestamp': datetime.now(timezone.utc).isoformat(),
                    'success': False,
                    'error': str(result),
                    'response_time': None,
                    'status_code': None
                })
            else:
                processed_results.append(result)

        return processed_results


# –£–ø—Ä–æ—â–µ–Ω–Ω—ã–π –∫–ª–∞—Å—Å –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ (–±–µ–∑ PostgreSQL)
class SimpleResultsStorage:
    @staticmethod
    def save_results_to_file(results: List[Dict], filename: str = "monitoring_results.json"):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ JSON —Ñ–∞–π–ª"""
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False)
        logger.info(f"–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ —Ñ–∞–π–ª: {filename}")


async def monitor_endpoints(urls: List[str]):
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ —ç–Ω–¥–ø–æ–∏–Ω—Ç–æ–≤"""
    tester = EndpointTester(max_concurrent=20, timeout=15)

    try:
        # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —ç–Ω–¥–ø–æ–∏–Ω—Ç–æ–≤
        logger.info(f"–ù–∞—á–∏–Ω–∞–µ–º —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ {len(urls)} —ç–Ω–¥–ø–æ–∏–Ω—Ç–æ–≤...")
        results = await tester.test_multiple_endpoints(urls)

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        successful = sum(1 for r in results if r['success'])
        failed = len(urls) - successful
        avg_response_time = sum(r.get('response_time', 0) for r in results if r['success']) / max(successful, 1)

        logger.info(f"–£—Å–ø–µ—à–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤: {successful}/{len(urls)}")
        logger.info(f"–°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –æ—Ç–≤–µ—Ç–∞: {avg_response_time:.3f}s")

        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Å–≤–æ–¥–∫—É –≤ Telegram
        try:
            telegram_service.send_monitoring_summary(
                total_urls=len(urls),
                successful=successful,
                failed=failed,
                avg_response_time=avg_response_time if successful > 0 else None
            )
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ —Å–≤–æ–¥–∫–∏ –≤ Telegram: {e}")

        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        SimpleResultsStorage.save_results_to_file(results)

        return results

    finally:
        await tester.close_session()


# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∫—Ä–∞—Å–∏–≤–æ–≥–æ –≤—ã–≤–æ–¥–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
def print_detailed_results(results: List[Dict]):
    """–ö—Ä–∞—Å–∏–≤—ã–π –≤—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""
    for i, result in enumerate(results, 1):
        print(f"\n{'=' * 60}")
        print(f"–†–ï–ó–£–õ–¨–¢–ê–¢ #{i}: {result['url']}")
        print(f"{'=' * 60}")

        print(f"‚úÖ –°—Ç–∞—Ç—É—Å: {'–£–°–ü–ï–•' if result['success'] else '–û–®–ò–ë–ö–ê'}")
        print(f"üìä –ö–æ–¥ –æ—Ç–≤–µ—Ç–∞: {result.get('status_code', 'N/A')}")
        print(f"‚è±Ô∏è  –í—Ä–µ–º—è –æ—Ç–≤–µ—Ç–∞: {result.get('response_time', 0):.3f}s")
        print(f"üîí HTTPS: {'–î–∞' if result.get('is_https') else '–ù–µ—Ç'}")

        if result.get('error'):
            print(f"‚ùå –û—à–∏–±–∫–∞: {result['error']}")

        # –¢–µ—Ö–Ω–æ–ª–æ–≥–∏–∏
        if result.get('technology_stack'):
            print(f"üõ†Ô∏è  –¢–µ—Ö–Ω–æ–ª–æ–≥–∏–∏: {', '.join(result['technology_stack'])}")

        # –ó–∞–≥–æ–ª–æ–≤–∫–∏ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏
        security_headers = result.get('security_headers', {})
        if any(security_headers.values()):
            print("üîê Security Headers:")
            for key, value in security_headers.items():
                if value:
                    print(f"   ‚Ä¢ {key}: {value}")

        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏
        checks = result.get('additional_checks', {})
        if checks:
            print("üìã –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏:")
            for check_name, check_data in checks.items():
                exists = check_data.get('exists', False)
                status = "‚úÖ –ï—Å—Ç—å" if exists else "‚ùå –ù–µ—Ç"
                print(f"   ‚Ä¢ {check_name}: {status}")
